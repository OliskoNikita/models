{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"aBMnJ2XLi8fz","executionInfo":{"status":"ok","timestamp":1747324997188,"user_tz":-180,"elapsed":120154,"user":{"displayName":"Oli","userId":"15742951886801697143"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a6544256-85a1-4e51-8f87-4e0cbef247c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aUV-_Hp7ibgQ","executionInfo":{"status":"ok","timestamp":1747324863811,"user_tz":-180,"elapsed":113895,"user":{"displayName":"Oli","userId":"15742951886801697143"}},"outputId":"402a7582-bfc2-4efd-a656-58838f0949c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting segmentation_models_pytorch\n","  Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (0.31.1)\n","Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (2.0.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (11.2.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (0.5.3)\n","Requirement already satisfied: timm>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (1.0.15)\n","Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (2.6.0+cu124)\n","Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (0.21.0+cu124)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from segmentation_models_pytorch) (4.67.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (2025.3.2)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (4.13.2)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (1.1.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8->segmentation_models_pytorch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8->segmentation_models_pytorch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8->segmentation_models_pytorch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8->segmentation_models_pytorch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8->segmentation_models_pytorch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8->segmentation_models_pytorch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8->segmentation_models_pytorch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8->segmentation_models_pytorch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8->segmentation_models_pytorch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8->segmentation_models_pytorch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation_models_pytorch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->segmentation_models_pytorch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->segmentation_models_pytorch) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (2025.4.26)\n","Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl (154 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, segmentation_models_pytorch\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 segmentation_models_pytorch-0.5.0\n","Collecting git+https://github.com/lucasb-eyer/pydensecrf.git\n","  Cloning https://github.com/lucasb-eyer/pydensecrf.git to /tmp/pip-req-build-wm1ae779\n","  Running command git clone --filter=blob:none --quiet https://github.com/lucasb-eyer/pydensecrf.git /tmp/pip-req-build-wm1ae779\n","  Resolved https://github.com/lucasb-eyer/pydensecrf.git to commit 2723c7fa4f2ead16ae1ce3d8afe977724bb8f87f\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: pydensecrf\n","  Building wheel for pydensecrf (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pydensecrf: filename=pydensecrf-1.0-cp311-cp311-linux_x86_64.whl size=3440333 sha256=8d4773e4b4722ac9632326eec6b276086ef15ec4c2fc94f7c3864a616d2d55d2\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-kwadmqz7/wheels/ce/8e/34/6dcfa200a9e2ae3627d8009b8bd1ca9b24512bec50a93304de\n","Successfully built pydensecrf\n","Installing collected packages: pydensecrf\n","Successfully installed pydensecrf-1.0\n"]}],"source":["!pip install segmentation_models_pytorch\n","!pip install git+https://github.com/lucasb-eyer/pydensecrf.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fR0zZ51_iwMS"},"outputs":[],"source":["import numpy as np\n","import segmentation_models_pytorch as smp\n","import torch\n","import os\n","import cv2\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap, BoundaryNorm\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","import torch.nn.functional as F\n","import glob\n","from tqdm import tqdm\n","import albumentations as A\n","import tifffile\n","from torch.amp import autocast\n","from torch.amp import GradScaler\n","import logging\n","import pydensecrf.densecrf as dcrf\n","from pydensecrf.utils import unary_from_softmax, create_pairwise_gaussian, create_pairwise_bilateral"]},{"cell_type":"code","source":["!cp -r /content/drive/MyDrive/datasets_and_models/HandLabeled.zip /content/"],"metadata":{"id":"cWmrAilPOVDj"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X041hNRt6RmL"},"outputs":[],"source":["!unzip /content/HandLabeled.zip -d /"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tm17yBCti-1I"},"outputs":[],"source":["# Параметры конфигурации\n","train_dir = \"/content/dataset_sen1floods11_RGB_NIR_VV_VH/train/Handlabeled\"\n","validation_dir = \"/content/dataset_sen1floods11_RGB_NIR_VV_VH/validation\"\n","test_dir = \"/content/dataset_sen1floods11_RGB_NIR_VV_VH/test\"\n","test_Bolivia_dir = \"/content/dataset_sen1floods11_RGB_NIR_VV_VH/test_Bolivia\"\n","local_batch_size = 64\n","learning_rate = 1e-3\n","num_epochs = 200\n","model_serialization = \"PAN_MobileNetV2\"\n","folder = \"PAN_MobileNetV2\"\n","channels = \"RGB_NIR\"\n","data = \"HandLabeled\""]},{"cell_type":"code","source":["# Предопределённые списки для преобразований D4 и их инверсии\n","D4_TRANSFORMS = [\n","    lambda x: x,                                 # I\n","    lambda x: torch.rot90(x, 1, [2, 3]),         # R90\n","    lambda x: torch.rot90(x, 2, [2, 3]),         # R180\n","    lambda x: torch.rot90(x, 3, [2, 3]),         # R270\n","    lambda x: torch.flip(x, [3]),                # F\n","    lambda x: torch.rot90(torch.flip(x, [3]), 1, [2, 3]),  # F_R90\n","    lambda x: torch.rot90(torch.flip(x, [3]), 2, [2, 3]),  # F_R180\n","    lambda x: torch.rot90(torch.flip(x, [3]), 3, [2, 3]),  # F_R270\n","]\n","\n","INVERSE_TRANSFORMS = [\n","    lambda x: x,                                 # I\n","    lambda x: torch.rot90(x, -1, [2, 3]),        # R90\n","    lambda x: torch.rot90(x, -2, [2, 3]),        # R180\n","    lambda x: torch.rot90(x, -3, [2, 3]),        # R270\n","    lambda x: torch.flip(x, [3]),                # F\n","    lambda x: torch.flip(torch.rot90(x, -1, [2, 3]), [3]),  # F_R90\n","    lambda x: torch.flip(torch.rot90(x, -2, [2, 3]), [3]),  # F_R180\n","    lambda x: torch.flip(torch.rot90(x, -3, [2, 3]), [3]),  # F_R270\n","]"],"metadata":{"id":"dOA4ypKoZG-I"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fR9riNiAjCxZ"},"outputs":[],"source":["transform = A.Compose([\n","    A.HorizontalFlip(p = 0.5),\n","    A.RandomRotate90(p = 0.5),\n","    A.VerticalFlip(p = 0.5)\n","])"]},{"cell_type":"code","source":["def get_filename(filepath):\n","    return os.path.split(filepath)[1]"],"metadata":{"id":"rhBkFAtKBsLd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_df(main_dir):\n","    rgb_nir_image_paths = sorted(glob.glob(main_dir + '/RGB+NIR/*.tif', recursive=True))\n","    rgb_nir_image_names = [get_filename(pth) for pth in rgb_nir_image_paths]\n","    mask_paths = []\n","\n","    for i in range(len(rgb_nir_image_paths)):\n","        # Путь к изображению vh\n","        mask_name = rgb_nir_image_names[i]\n","        parts = mask_name.split('_')\n","        mask_name = '_'.join(parts[:3]) + '_'\n","        mask_path = os.path.join(\n","            main_dir, \"Label\", f\"{mask_name}LabelHand.tif\"\n","        )\n","        mask_paths.append(mask_path)\n","\n","    paths = {\n","        \"rgb_nir_image_path\": rgb_nir_image_paths,\n","        \"mask_path\": mask_paths,\n","    }\n","\n","    return pd.DataFrame(paths)"],"metadata":{"id":"yHBg5fukBmWx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MyDataset(Dataset):\n","    def __init__(self, dataframe, split, transform=None):\n","        self.split = split\n","        self.dataset = dataframe\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return self.dataset.shape[0]\n","\n","    def __getitem__(self, index):\n","\n","        row = self.dataset.iloc[index]\n","        img_path = row[\"rgb_nir_image_path\"]\n","        mask_path = row[\"mask_path\"]\n","\n","        # Загружаем 4-канальное изображение TIFF (R, G, B, NIR)\n","        image = tifffile.imread(img_path).astype(np.float32)\n","        # Нормируем [0, 1]\n","        image = image/10000.0\n","        image = np.clip(image, 0.0, 1.0)\n","        image = image.transpose(1, 2, 0)\n","        # Загружаем маску (одноканальная)\n","        mask = tifffile.imread(mask_path).astype(np.int64)\n","\n","        # Аугментация только для train\n","        if self.split == \"train\" and self.transform is not None:\n","            augmented = self.transform(image=image, mask=mask)\n","            image = augmented[\"image\"]\n","            mask = augmented[\"mask\"]\n","        # Транспонируем каналы для PyTorch (C, H, W)\n","        image = image.transpose(2, 0, 1)\n","\n","        return {\n","                \"image\": torch.from_numpy(image.astype(np.float32)),\n","                \"mask\": torch.from_numpy(mask).long()\n","            }"],"metadata":{"id":"9jR8m5jPse00"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_TP_FP_TN_FN(pred, target):\n","    # Получаем предсказанные метки (из логитов)\n","    pred_labels = pred.argmax(dim=1)  # dim=1 — классы, на выходе (B, H, W)\n","\n","    TP = ((pred_labels == 1) & (target == 1)).sum().item()\n","    FP = ((pred_labels == 1) & (target == 0)).sum().item()\n","    TN = ((pred_labels == 0) & (target == 0)).sum().item()\n","    FN = ((pred_labels == 0) & (target == 1)).sum().item()\n","\n","    return float(TP), float(FP), float(TN), float(FN), float(TN), float(FN), float(TP), float(FP)"],"metadata":{"id":"1bBAIWdCYPBG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_metrics(TP_flood, FP_flood, TN_flood, FN_flood, TP_background, FP_background, TN_background, FN_background):\n","    Accuracy = (TP_flood + TN_flood)/(TP_flood + FP_flood + TN_flood + FN_flood + 1e-6)\n","    IoU_flood = TP_flood/(TP_flood + FP_flood + FN_flood + 1e-6)\n","    IoU_background = TP_background/(TP_background + FP_background + FN_background + 1e-6)\n","    IoU = (IoU_flood + IoU_background)/2\n","    Dice_flood = 2*TP_flood/(2*TP_flood + FP_flood + FN_flood + 1e-6)\n","    Dice_background = 2*TP_background/(2*TP_background + FP_background + FN_background + 1e-6)\n","    Dice = (Dice_flood + Dice_background)/2\n","    Precision_flood = TP_flood/(TP_flood + FP_flood + 1e-6)\n","    Precision_background = TP_background/(TP_background + FP_background + 1e-6)\n","    Precision = (Precision_flood + Precision_background)/2\n","    Recall_flood = TP_flood/(TP_flood + FN_flood + 1e-6)\n","    Recall_background = TP_background/(TP_background + FN_background + 1e-6)\n","    Recall = (Recall_flood + Recall_background)/2\n","    BalancedAccuracy = (TP_flood/(TP_flood + FN_flood + 1e-6) + TN_flood/(TN_flood + FP_flood + 1e-6))/2\n","\n","    return Accuracy, IoU_flood, IoU_background, IoU, Dice_flood, Dice_background, Dice, Precision_flood, Precision_background, Precision, Recall_flood, Recall_background, Recall, BalancedAccuracy"],"metadata":{"id":"JNCw4MQaPa-v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def d4_mask_batch(images: torch.Tensor, model: torch.nn.Module, device=\"cuda\" if torch.cuda.is_available() else \"cpu\") -> torch.Tensor:\n","    \"\"\"\n","    Test-Time D4-аугментация: возвращает усреднённые вероятности классов (B,2,H,W).\n","    \"\"\"\n","    model.eval()\n","    images = images.to(device)\n","    B, C, H, W = images.shape\n","    acc = torch.zeros((B, 2, H, W), dtype=torch.float32, device=device)\n","\n","    with torch.no_grad():\n","        for transform, inv in zip(D4_TRANSFORMS, INVERSE_TRANSFORMS):\n","\n","            imgs_t = transform(images)\n","\n","            logits = model(imgs_t)                  # (B,2,H,W)\n","            prob = F.softmax(logits, dim=1)\n","            prob_inv = inv(prob)\n","            acc += prob_inv\n","\n","    # Усреднение по 8 вариантам\n","    avg = acc / len(D4_TRANSFORMS)          # (B,2,H,W)\n","    return avg"],"metadata":{"id":"zmdO2W5CZM7T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def apply_crf_to_batch(images, probs, n_iters=10):\n","    \"\"\"\n","    Применяет CRF к батчу изображений.\n","\n","    :param images: тензор изображений формы (B, C, H, W), где C >= 3\n","    :param probs: тензор вероятностей классов формы (B, 2, H, W)\n","    :param n_iters: количество итераций для CRF\n","    :return: тензор уточнённых масок формы (B, H, W)\n","    \"\"\"\n","    B, C, H, W = probs.shape\n","    device = images.device\n","    refined_masks = torch.zeros((B, 2, H, W), dtype = torch.uint8, device = device)\n","    for i in range(B):\n","        # Извлекаем первые три канала изображения и масштабируем в диапазон [0, 255]\n","        image_rgb = (images[i, 1:4, :, :] * 255).cpu().numpy().transpose(1, 2, 0).copy().astype(np.uint8)\n","\n","        # Получаем вероятности классов\n","        prob = probs[i].cpu().numpy()\n","\n","        # Инициализация CRF\n","        d = dcrf.DenseCRF2D(W, H, 2)\n","        unary = unary_from_softmax(prob)\n","        d.setUnaryEnergy(unary)\n","\n","        # Добавление парных потенциалов\n","        d.addPairwiseGaussian(sxy=3, compat=3)\n","        d.addPairwiseBilateral(sxy=80, srgb=13, rgbim=image_rgb, compat=10)\n","\n","        # Инференс CRF\n","        Q = d.inference(n_iters)\n","        refined_mask = np.array(Q).reshape((2, H, W)).astype(np.float32)\n","\n","        refined_masks[i] = torch.tensor(refined_mask, dtype = torch.float32, device = device)\n","\n","    return refined_masks"],"metadata":{"id":"hBBadV2C7hVM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_flood_percentage(mask):\n","    flood_pixels = np.sum(mask == 1)\n","    total_pixels = mask.size\n","    return (flood_pixels / total_pixels) * 100"],"metadata":{"id":"fjObhVeVxJ60"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def visualize_predictions(images, masks, predictions):\n","    \"\"\"\n","    Визуализация входных изображений, их масок и предсказаний модели.\n","    Порядок отображения: RGB-изображение, NIR-канал, маска, предсказание модели.\n","    \"\"\"\n","    cmap = ListedColormap(['black', '#ffc0cb', '#0000FF'])  # Цвета для -1, 0, 1\n","    bounds = [-1.5, -0.5, 0.5, 1.5]  # Границы значений\n","    norm = BoundaryNorm(bounds, cmap.N)\n","\n","    batch_size = images.shape[0]\n","    for i in range(batch_size):\n","        # Извлечение изображения и маски\n","        image = images[i].permute(1, 2, 0).cpu().numpy()  # Перестановка осей и перевод на CPU\n","        mask = masks[i].cpu().numpy()  # Перевод маски на CPU\n","        prediction = predictions[i].argmax(dim=0).cpu().numpy()  # Перевод предсказания на CPU\n","\n","        # Извлечение RGB и NIR каналов\n","        rgb_image = image[:, :, :3]\n","        if image.shape[2] > 3:\n","            nir_channel = image[:, :, 3]\n","        else:\n","            nir_channel = None  # Если NIR-канал отсутствует\n","\n","        # Расчёт процента затопления\n","        flood_percentage = calculate_flood_percentage(prediction)\n","\n","        # Отображение изображений\n","        fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n","\n","        # RGB-изображение\n","        rgb_image = np.clip(rgb_image * 6.0, 0, 1)\n","        axes[0].imshow(rgb_image)\n","        axes[0].set_title(\"RGB изображение\")\n","        axes[0].axis(\"off\")\n","\n","        # NIR-канал\n","        if nir_channel is not None:\n","            axes[1].imshow(nir_channel, cmap=\"gray\")\n","            axes[1].set_title(\"NIR канал\")\n","        else:\n","            axes[1].text(0.5, 0.5, 'NIR канал отсутствует', horizontalalignment='center', verticalalignment='center')\n","            axes[1].set_title(\"NIR канал\")\n","        axes[1].axis(\"off\")\n","\n","        # Маска\n","        axes[2].imshow(mask, cmap=cmap, norm=norm)\n","        axes[2].set_title(\"Маска\")\n","        axes[2].axis(\"off\")\n","\n","        # Предсказание модели\n","        axes[3].imshow(prediction, cmap=cmap, norm=norm)\n","        axes[3].set_title(f\"Сегментация модели\\n{flood_percentage:.2f}% воды\")\n","        axes[3].axis(\"off\")\n","\n","        plt.tight_layout()\n","        plt.show()"],"metadata":{"id":"7CYmTikPxROQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QHzHelBpjU9D"},"outputs":[],"source":["def train(num_epochs = 200):\n","\n","    global validation_iou\n","    global num_best_epoch\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # Создание модели\n","    model = smp.PAN(\n","        encoder_name= \"mobilenet_v2\", encoder_weights='imagenet', in_channels=4, classes=2\n","    ).to(device)\n","\n","    # Оптимизатор\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    # Шедулер\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","        optimizer,\n","        T_0=25,\n","        T_mult=1,\n","        eta_min=5e-6\n","    )\n","\n","    scaler = GradScaler('cuda')\n","\n","    # Функция потерь\n","    criterion_dice = smp.losses.DiceLoss(mode=\"multiclass\", ignore_index=-1)\n","\n","    # Создание DataLoader-ов\n","    train_df = create_df(train_dir)\n","    validation_df = create_df(validation_dir)\n","    if train_df.empty:\n","        raise ValueError(\"Train DataFrame is empty!\")\n","    if validation_df.empty:\n","        raise ValueError(\"Validation DataFrame is empty!\")\n","\n","    train_dataset = MyDataset(train_df, split=\"train\", transform = transform)\n","    validation_dataset = MyDataset(validation_df, split=\"validation\", transform=None)\n","\n","    train_loader = DataLoader(\n","        train_dataset, batch_size=local_batch_size, shuffle=True, num_workers = os.cpu_count()-1,\n","        pin_memory=True, persistent_workers=True\n","    )\n","    validation_loader = DataLoader(\n","        validation_dataset, batch_size=local_batch_size, shuffle=False, num_workers = os.cpu_count()-1,\n","        pin_memory=True, persistent_workers=True\n","    )\n","    if len(train_loader) == 0:\n","        raise ValueError(\"Train DataLoader is empty!\")\n","    if len(validation_loader) == 0:\n","        raise ValueError(\"Validation DataLoader is empty!\")\n","\n","    ## Начало обучения ##\n","    for epoch in range(num_epochs):\n","        # Тренировочный этап\n","        model.train()\n","        train_losses = []\n","        TP_flood, FP_flood, TN_flood, FN_flood = 0.0, 0.0, 0.0, 0.0\n","        TP_background, FP_background, TN_background, FN_background = 0.0, 0.0, 0.0, 0.0\n","\n","        progress_bar = tqdm(train_loader, desc=\"Train\", unit=\"batch\", leave=True)\n","        for batch in progress_bar:\n","\n","            image = batch[\"image\"].to(device, non_blocking=True)\n","            mask = batch[\"mask\"].to(device, non_blocking=True)\n","\n","            optimizer.zero_grad()\n","\n","            with autocast('cuda'):\n","                pred = model(image)\n","                loss = criterion_dice(pred, mask)\n","\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","\n","            train_losses.append(loss.item())\n","            TP_flood_batch, FP_flood_batch, TN_flood_batch, FN_flood_batch, TP_background_batch, FP_background_batch, TN_background_batch, FN_background_batch = calculate_TP_FP_TN_FN(pred, mask)\n","            TP_flood += TP_flood_batch\n","            FP_flood += FP_flood_batch\n","            TN_flood += TN_flood_batch\n","            FN_flood += FN_flood_batch\n","            TP_background += TP_background_batch\n","            FP_background += FP_background_batch\n","            TN_background += TN_background_batch\n","            FN_background += FN_background_batch\n","\n","        Avg_loss = sum(train_losses) / (len(train_losses) + 1e-6)\n","        Accuracy, IoU_flood, IoU_background, IoU, Dice_flood, Dice_background, Dice, Precision_flood, Precision_background, Precision, Recall_flood, Recall_background, Recall, BalancedAccuracy = calculate_metrics(TP_flood = TP_flood, FP_flood = FP_flood, TN_flood = TN_flood, FN_flood = FN_flood, TP_background = TP_background, FP_background = FP_background, TN_background = TN_background, FN_background = FN_background)\n","        logger1.info(f\"Epoch {epoch+1}, LR: {optimizer.param_groups[0]['lr']:.8f}, Train Loss: {Avg_loss:.4f}, Train IoU: {IoU:.4f}, Train Accuracy: {Accuracy:.4f}, Train Dice: {Dice:.4f}, Train Precision: {Precision:.4f}, Train Recall: {Recall:.4f}, Train BalancedAccuracy: {BalancedAccuracy:.4f}, Train IoU_flood: {IoU_flood:.4f}, Train IoU_background: {IoU_background:.4f}, Train Dice_flood: {Dice_flood:.4f}, Train Dice_background: {Dice_background:.4f}, Train Precision_flood: {Precision_flood:.4f}, Train Precision_background: {Precision_background:.4f}, Train Recall_flood: {Recall_flood:.4f}, Train Recall_background: {Recall_background:.4f}\")\n","\n","        scheduler.step()\n","\n","        # Оценка на валидационном наборе\n","        model.eval()\n","        with torch.no_grad():\n","            valid_losses = []\n","            TP_flood, FP_flood, TN_flood, FN_flood = 0.0, 0.0, 0.0, 0.0\n","            TP_background, FP_background, TN_background, FN_background = 0.0, 0.0, 0.0, 0.0\n","\n","            progress_bar = tqdm(validation_loader, desc=\"Valid\", unit=\"batch\", leave=True)\n","            for batch in progress_bar:\n","                image = batch[\"image\"].to(device, non_blocking=True)\n","                mask = batch[\"mask\"].to(device, non_blocking=True)\n","\n","                with autocast('cuda'):\n","                    pred = model(image)\n","                    loss = criterion_dice(pred, mask)\n","\n","                # Метрики\n","                valid_losses.append(loss.item())\n","                TP_flood_batch, FP_flood_batch, TN_flood_batch, FN_flood_batch, TP_background_batch, FP_background_batch, TN_background_batch, FN_background_batch = calculate_TP_FP_TN_FN(pred, mask)\n","                TP_flood += TP_flood_batch\n","                FP_flood += FP_flood_batch\n","                TN_flood += TN_flood_batch\n","                FN_flood += FN_flood_batch\n","                TP_background += TP_background_batch\n","                FP_background += FP_background_batch\n","                TN_background += TN_background_batch\n","                FN_background += FN_background_batch\n","\n","        Avg_loss = sum(valid_losses) / (len(valid_losses) + 1e-6)\n","        Accuracy, IoU_flood, IoU_background, IoU, Dice_flood, Dice_background, Dice, Precision_flood, Precision_background, Precision, Recall_flood, Recall_background, Recall, BalancedAccuracy = calculate_metrics(TP_flood = TP_flood, FP_flood = FP_flood, TN_flood = TN_flood, FN_flood = FN_flood, TP_background = TP_background, FP_background = FP_background, TN_background = TN_background, FN_background = FN_background)\n","        if IoU > validation_iou:\n","            num_best_epoch = epoch + 1\n","            validation_iou = IoU\n","        logger1.info(f\"Epoch {epoch+1}, Valid Loss: {Avg_loss:.4f}, Valid IoU: {IoU:.4f}, Valid Accuracy: {Accuracy:.4f}, Valid Dice: {Dice:.4f}, Valid Precision: {Precision:.4f}, Valid Recall: {Recall:.4f}, Valid BalancedAccuracy: {BalancedAccuracy:.4f}, Valid IoU_flood: {IoU_flood:.4f}, Valid IoU_background: {IoU_background:.4f}, Valid Dice_flood: {Dice_flood:.4f}, Valid Dice_background: {Dice_background:.4f}, Valid Precision_flood: {Precision_flood:.4f}, Valid Precision_background: {Precision_background:.4f}, Valid Recall_flood: {Recall_flood:.4f}, Valid Recall_background: {Recall_background:.4f}\")\n","\n","        # Сохранение модели\n","        torch.save({\n","            'epoch': epoch+1,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'scheduler_state_dict': scheduler.state_dict(),\n","            'loss': Avg_loss\n","        }, f\"/content/drive/MyDrive/datasets_and_models/{folder}/{folder_of_weights}/{model_serialization}_{epoch+1}_{channels}_{data}.pth\")\n"]},{"cell_type":"code","source":["def addtrain(num_epochs = 200, initEpoch = 100):\n","\n","    global validation_iou\n","    global num_best_epoch\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    checkpoint = torch.load(f\"/content/drive/MyDrive/datasets_and_models/{folder}/{folder_of_weights}/{model_serialization}_{initEpoch}_{channels}_{data}.pth\", map_location=device)\n","\n","    # Создание модели\n","    model = smp.PAN(\n","        encoder_name=\"mobilenet_v2\", encoder_weights='imagenet', in_channels=4, classes=2\n","    ).to(device)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","\n","    # Оптимизатор\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","\n","    # Шедулер\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","        optimizer,\n","        T_0=25,\n","        T_mult=1,\n","        eta_min=5e-6\n","    )\n","    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","\n","    scaler = GradScaler('cuda')\n","\n","    # Функция потерь\n","    criterion_dice = smp.losses.DiceLoss(mode=\"multiclass\", ignore_index=-1)\n","\n","    # Создание DataLoader-ов\n","    train_df = create_df(train_dir)\n","    validation_df = create_df(validation_dir)\n","    if train_df.empty:\n","        raise ValueError(\"Train DataFrame is empty!\")\n","    if validation_df.empty:\n","        raise ValueError(\"Validation DataFrame is empty!\")\n","\n","    train_dataset = MyDataset(train_df, split=\"train\", transform = transform)\n","    validation_dataset = MyDataset(validation_df, split=\"validation\", transform=None)\n","\n","    train_loader = DataLoader(\n","        train_dataset, batch_size=local_batch_size, shuffle=True, num_workers = os.cpu_count()-1,\n","        pin_memory=True, persistent_workers=True\n","    )\n","    validation_loader = DataLoader(\n","        validation_dataset, batch_size=local_batch_size, shuffle=False, num_workers = os.cpu_count()-1,\n","        pin_memory=True, persistent_workers=True\n","    )\n","    if len(train_loader) == 0:\n","        raise ValueError(\"Train DataLoader is empty!\")\n","    if len(validation_loader) == 0:\n","        raise ValueError(\"Validation DataLoader is empty!\")\n","\n","    ## Начало обучения ##\n","    for epoch in range(num_epochs):\n","        # Тренировочный этап\n","        model.train()\n","        train_losses = []\n","        TP_flood, FP_flood, TN_flood, FN_flood = 0.0, 0.0, 0.0, 0.0\n","        TP_background, FP_background, TN_background, FN_background = 0.0, 0.0, 0.0, 0.0\n","\n","        progress_bar = tqdm(train_loader, desc=\"Train\", unit=\"batch\", leave=True)\n","        for batch in progress_bar:\n","\n","            image = batch[\"image\"].to(device, non_blocking=True)\n","            mask = batch[\"mask\"].to(device, non_blocking=True)\n","\n","            optimizer.zero_grad()\n","\n","            with autocast('cuda'):\n","                pred = model(image)\n","                loss = criterion_dice(pred, mask)\n","\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","\n","            train_losses.append(loss.item())\n","            TP_flood_batch, FP_flood_batch, TN_flood_batch, FN_flood_batch, TP_background_batch, FP_background_batch, TN_background_batch, FN_background_batch = calculate_TP_FP_TN_FN(pred, mask)\n","            TP_flood += TP_flood_batch\n","            FP_flood += FP_flood_batch\n","            TN_flood += TN_flood_batch\n","            FN_flood += FN_flood_batch\n","            TP_background += TP_background_batch\n","            FP_background += FP_background_batch\n","            TN_background += TN_background_batch\n","            FN_background += FN_background_batch\n","\n","        Avg_loss = sum(train_losses) / (len(train_losses) + 1e-6)\n","        Accuracy, IoU_flood, IoU_background, IoU, Dice_flood, Dice_background, Dice, Precision_flood, Precision_background, Precision, Recall_flood, Recall_background, Recall, BalancedAccuracy = calculate_metrics(TP_flood = TP_flood, FP_flood = FP_flood, TN_flood = TN_flood, FN_flood = FN_flood, TP_background = TP_background, FP_background = FP_background, TN_background = TN_background, FN_background = FN_background)\n","        logger1.info(f\"Epoch {epoch+initEpoch+1}, LR: {optimizer.param_groups[0]['lr']:.8f}, Train Loss: {Avg_loss:.4f}, Train IoU: {IoU:.4f}, Train Accuracy: {Accuracy:.4f}, Train Dice: {Dice:.4f}, Train Precision: {Precision:.4f}, Train Recall: {Recall:.4f}, Train BalancedAccuracy: {BalancedAccuracy:.4f}, Train IoU_flood: {IoU_flood:.4f}, Train IoU_background: {IoU_background:.4f}, Train Dice_flood: {Dice_flood:.4f}, Train Dice_background: {Dice_background:.4f}, Train Precision_flood: {Precision_flood:.4f}, Train Precision_background: {Precision_background:.4f}, Train Recall_flood: {Recall_flood:.4f}, Train Recall_background: {Recall_background:.4f}\")\n","\n","        scheduler.step()\n","\n","        # Оценка на валидационном наборе\n","        model.eval()\n","        with torch.no_grad():\n","            valid_losses = []\n","            TP_flood, FP_flood, TN_flood, FN_flood = 0.0, 0.0, 0.0, 0.0\n","            TP_background, FP_background, TN_background, FN_background = 0.0, 0.0, 0.0, 0.0\n","\n","            progress_bar = tqdm(validation_loader, desc=\"Valid\", unit=\"batch\", leave=True)\n","            for batch in progress_bar:\n","                image = batch[\"image\"].to(device, non_blocking=True)\n","                mask = batch[\"mask\"].to(device, non_blocking=True)\n","\n","                with autocast('cuda'):\n","                    pred = model(image)\n","                    loss = criterion_dice(pred, mask)\n","\n","                # Метрики\n","                valid_losses.append(loss.item())\n","                TP_flood_batch, FP_flood_batch, TN_flood_batch, FN_flood_batch, TP_background_batch, FP_background_batch, TN_background_batch, FN_background_batch = calculate_TP_FP_TN_FN(pred, mask)\n","                TP_flood += TP_flood_batch\n","                FP_flood += FP_flood_batch\n","                TN_flood += TN_flood_batch\n","                FN_flood += FN_flood_batch\n","                TP_background += TP_background_batch\n","                FP_background += FP_background_batch\n","                TN_background += TN_background_batch\n","                FN_background += FN_background_batch\n","\n","        Avg_loss = sum(valid_losses) / (len(valid_losses) + 1e-6)\n","        Accuracy, IoU_flood, IoU_background, IoU, Dice_flood, Dice_background, Dice, Precision_flood, Precision_background, Precision, Recall_flood, Recall_background, Recall, BalancedAccuracy = calculate_metrics(TP_flood = TP_flood, FP_flood = FP_flood, TN_flood = TN_flood, FN_flood = FN_flood, TP_background = TP_background, FP_background = FP_background, TN_background = TN_background, FN_background = FN_background)\n","        if IoU > validation_iou:\n","            num_best_epoch = epoch + initEpoch +1\n","            validation_iou = IoU\n","        logger1.info(f\"Epoch {epoch+initEpoch+1}, Valid Loss: {Avg_loss:.4f}, Valid IoU: {IoU:.4f}, Valid Accuracy: {Accuracy:.4f}, Valid Dice: {Dice:.4f}, Valid Precision: {Precision:.4f}, Valid Recall: {Recall:.4f}, Valid BalancedAccuracy: {BalancedAccuracy:.4f}, Valid IoU_flood: {IoU_flood:.4f}, Valid IoU_background: {IoU_background:.4f}, Valid Dice_flood: {Dice_flood:.4f}, Valid Dice_background: {Dice_background:.4f}, Valid Precision_flood: {Precision_flood:.4f}, Valid Precision_background: {Precision_background:.4f}, Valid Recall_flood: {Recall_flood:.4f}, Valid Recall_background: {Recall_background:.4f}\")\n","\n","        # Сохранение модели\n","        torch.save({\n","            'epoch': epoch+initEpoch+1,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'scheduler_state_dict': scheduler.state_dict(),\n","            'loss': Avg_loss\n","        }, f\"/content/drive/MyDrive/datasets_and_models/{folder}/{folder_of_weights}/{model_serialization}_{epoch+initEpoch+1}_{channels}_{data}.pth\")\n"],"metadata":{"id":"A3bwM48MAfSX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test(TestEpoch = 200):\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    checkpoint = torch.load(f\"/content/drive/MyDrive/datasets_and_models/{folder}/{folder_of_weights}/{model_serialization}_{TestEpoch}_{channels}_{data}.pth\", map_location=device)\n","\n","    # Создание модели\n","    model = smp.PAN(\n","        encoder_name=\"mobilenet_v2\", encoder_weights='imagenet', in_channels=4, classes=2\n","    ).to(device)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","\n","    scaler = GradScaler('cuda')\n","\n","    # Создание DataLoader-ов\n","    test_df = create_df(test_dir)\n","    test_Bolivia_df = create_df(test_Bolivia_dir)\n","    if test_df.empty:\n","        raise ValueError(\"Test DataFrame is empty!\")\n","    if  test_Bolivia_df.empty:\n","        raise ValueError(\"Test Bolivia DataFrame is empty!\")\n","\n","    test_dataset = MyDataset(test_df, split=\"test\", transform = None)\n","    test_Bolivia_dataset = MyDataset(test_Bolivia_df, split=\"test\", transform=None)\n","\n","    test_loader = DataLoader(\n","        test_dataset, batch_size=16, shuffle=False, num_workers = os.cpu_count()-1,\n","        pin_memory=True, persistent_workers=True\n","    )\n","    test_Bolivia_loader = DataLoader(\n","        test_Bolivia_dataset, batch_size=16, shuffle=False, num_workers = os.cpu_count()-1,\n","        pin_memory=True, persistent_workers=True\n","    )\n","    if len(test_loader) == 0:\n","        raise ValueError(\"Test DataLoader is empty!\")\n","    if len(test_Bolivia_loader) == 0:\n","        raise ValueError(\"Test Bolivia DataLoader is empty!\")\n","\n","    # Оценка на тестовом наборе\n","    model.eval()\n","    with torch.no_grad():\n","        test_losses = []\n","        TP_flood, FP_flood, TN_flood, FN_flood = 0.0, 0.0, 0.0, 0.0\n","        TP_background, FP_background, TN_background, FN_background = 0.0, 0.0, 0.0, 0.0\n","        TP_flood_aug, FP_flood_aug, TN_flood_aug, FN_flood_aug = 0.0, 0.0, 0.0, 0.0\n","        TP_background_aug, FP_background_aug, TN_background_aug, FN_background_aug = 0.0, 0.0, 0.0, 0.0\n","        TP_flood_aug_crf, FP_flood_aug_crf, TN_flood_aug_crf, FN_flood_aug_crf = 0.0, 0.0, 0.0, 0.0\n","        TP_background_aug_crf, FP_background_aug_crf, TN_background_aug_crf, FN_background_aug_crf = 0.0, 0.0, 0.0, 0.0\n","\n","        progress_bar = tqdm(test_loader, desc=\"Test\", unit=\"batch\", leave=True)\n","        for batch in progress_bar:\n","            image = batch[\"image\"].to(device, non_blocking=True)\n","            mask = batch[\"mask\"].to(device, non_blocking=True)\n","\n","            with autocast('cuda'):\n","                pred = model(image)\n","\n","            pred_aug = d4_mask_batch(images = image, model = model, device = device)\n","            pred_aug_CRF = apply_crf_to_batch(images = image, probs = pred_aug)\n","\n","            #visualize_predictions(images = image , masks = mask, predictions = pred)\n","            #visualize_predictions(images = image , masks = mask, predictions = pred_aug)\n","            #visualize_predictions(images = image , masks = mask, predictions = pred_aug_CRF)\n","\n","            # Метрики\n","            TP_flood_batch, FP_flood_batch, TN_flood_batch, FN_flood_batch, TP_background_batch, FP_background_batch, TN_background_batch, FN_background_batch = calculate_TP_FP_TN_FN(pred, mask)\n","            TP_flood += TP_flood_batch\n","            FP_flood += FP_flood_batch\n","            TN_flood += TN_flood_batch\n","            FN_flood += FN_flood_batch\n","            TP_background += TP_background_batch\n","            FP_background += FP_background_batch\n","            TN_background += TN_background_batch\n","            FN_background += FN_background_batch\n","            TP_flood_batch, FP_flood_batch, TN_flood_batch, FN_flood_batch, TP_background_batch, FP_background_batch, TN_background_batch, FN_background_batch = calculate_TP_FP_TN_FN(pred_aug, mask)\n","            TP_flood_aug += TP_flood_batch\n","            FP_flood_aug += FP_flood_batch\n","            TN_flood_aug += TN_flood_batch\n","            FN_flood_aug += FN_flood_batch\n","            TP_background_aug += TP_background_batch\n","            FP_background_aug += FP_background_batch\n","            TN_background_aug += TN_background_batch\n","            FN_background_aug += FN_background_batch\n","            TP_flood_batch, FP_flood_batch, TN_flood_batch, FN_flood_batch, TP_background_batch, FP_background_batch, TN_background_batch, FN_background_batch = calculate_TP_FP_TN_FN(pred_aug_CRF, mask)\n","            TP_flood_aug_crf += TP_flood_batch\n","            FP_flood_aug_crf += FP_flood_batch\n","            TN_flood_aug_crf += TN_flood_batch\n","            FN_flood_aug_crf += FN_flood_batch\n","            TP_background_aug_crf += TP_background_batch\n","            FP_background_aug_crf += FP_background_batch\n","            TN_background_aug_crf += TN_background_batch\n","            FN_background_aug_crf += FN_background_batch\n","    print(f\"TP_flood = {TP_flood}, FP_flood = {FP_flood}, TN_flood = {TN_flood}, FN_flood = {FN_flood}\")\n","    print(f\"TP_flood_aug = {TP_flood_aug}, FP_flood_aug = {FP_flood_aug}, TN_flood_aug = {TN_flood_aug}, FN_flood_aug = {FN_flood_aug}\")\n","    print(f\"TP_floodaug_crf = {TP_flood_aug_crf}, FP_floodaug_crf = {FP_flood_aug_crf}, TN_floodaug_crf = {TN_flood_aug_crf}, FN_floodaug_crf = {FN_flood_aug_crf}\")\n","    Accuracy, IoU_flood, IoU_background, IoU, Dice_flood, Dice_background, Dice, Precision_flood, Precision_background, Precision, Recall_flood, Recall_background, Recall, BalancedAccuracy = calculate_metrics(TP_flood = TP_flood, FP_flood = FP_flood, TN_flood = TN_flood, FN_flood = FN_flood, TP_background = TP_background, FP_background = FP_background, TN_background = TN_background, FN_background = FN_background)\n","    Accuracy_aug, IoU_flood_aug, IoU_background_aug, IoU_aug, Dice_flood_aug, Dice_background_aug, Dice_aug, Precision_flood_aug, Precision_background_aug, Precision_aug, Recall_flood_aug, Recall_background_aug, Recall_aug, BalancedAccuracy_aug = calculate_metrics(TP_flood = TP_flood_aug, FP_flood = FP_flood_aug, TN_flood = TN_flood_aug, FN_flood = FN_flood_aug, TP_background = TP_background_aug, FP_background = FP_background_aug, TN_background = TN_background_aug, FN_background = FN_background_aug)\n","    Accuracy_aug_crf, IoU_flood_aug_crf, IoU_background_aug_crf, IoU_aug_crf, Dice_flood_aug_crf, Dice_background_aug_crf, Dice_aug_crf, Precision_flood_aug_crf, Precision_background_aug_crf, Precision_aug_crf, Recall_flood_aug_crf, Recall_background_aug_crf, Recall_aug_crf, BalancedAccuracy_aug_crf = calculate_metrics(TP_flood = TP_flood_aug_crf, FP_flood = FP_flood_aug_crf, TN_flood = TN_flood_aug_crf, FN_flood = FN_flood_aug_crf, TP_background = TP_background_aug_crf, FP_background = FP_background_aug_crf, TN_background = TN_background_aug_crf, FN_background = FN_background_aug_crf)\n","    logger2.info(f\"WeightsEpoch: {checkpoint['epoch']}, Test IoU: {IoU:.4f}, Test Accuracy: {Accuracy:.4f}, Test Dice: {Dice:.4f}, Test Precision: {Precision:.4f}, Test Recall: {Recall:.4f}, Test BalancedAccuracy: {BalancedAccuracy:.4f}, Test IoU_flood: {IoU_flood:.4f}, Test IoU_background: {IoU_background:.4f}, Test Dice_flood: {Dice_flood:.4f}, Test Dice_background: {Dice_background:.4f}, Test Precision_flood: {Precision_flood:.4f}, Test Precision_background: {Precision_background:.4f}, Test Recall_flood: {Recall_flood:.4f}, Test Recall_background: {Recall_background:.4f}\")\n","    logger2.info(f\"WeightsEpoch: {checkpoint['epoch']}, Test Aug IoU: {IoU_aug:.4f}, Test Accuracy: {Accuracy_aug:.4f}, Test Dice: {Dice_aug:.4f}, Test Precision: {Precision_aug:.4f}, Test Recall: {Recall_aug:.4f}, Test BalancedAccuracy: {BalancedAccuracy_aug:.4f}, Test IoU_flood: {IoU_flood_aug:.4f}, Test IoU_background: {IoU_background_aug:.4f}, Test Dice_flood: {Dice_flood_aug:.4f}, Test Dice_background: {Dice_background_aug:.4f}, Test Precision_flood: {Precision_flood_aug:.4f}, Test Precision_background: {Precision_background_aug:.4f}, Test Recall_flood: {Recall_flood_aug:.4f}, Test Recall_background: {Recall_background_aug:.4f}\")\n","    logger2.info(f\"WeightsEpoch: {checkpoint['epoch']}, Test Aug CRF IoU: {IoU_aug_crf:.4f}, Test Accuracy: {Accuracy_aug_crf:.4f}, Test Dice: {Dice_aug_crf:.4f}, Test Precision: {Precision_aug_crf:.4f}, Test Recall: {Recall_aug_crf:.4f}, Test BalancedAccuracy: {BalancedAccuracy_aug_crf:.4f}, Test IoU_flood: {IoU_flood_aug_crf:.4f}, Test IoU_background: {IoU_background_aug_crf:.4f}, Test Dice_flood: {Dice_flood_aug_crf:.4f}, Test Dice_background: {Dice_background_aug_crf:.4f}, Test Precision_flood: {Precision_flood_aug_crf:.4f}, Test Precision_background: {Precision_background_aug_crf:.4f}, Test Recall_flood: {Recall_flood_aug_crf:.4f}, Test Recall_background: {Recall_background_aug_crf:.4f}\")\n","\n","    # Оценка на тестовом наборе Боливии\n","    model.eval()\n","    with torch.no_grad():\n","        test_Bolivia_losses = []\n","        TP_flood, FP_flood, TN_flood, FN_flood = 0.0, 0.0, 0.0, 0.0\n","        TP_background, FP_background, TN_background, FN_background = 0.0, 0.0, 0.0, 0.0\n","\n","        progress_bar = tqdm(test_Bolivia_loader, desc=\"Test Bolivia\", unit=\"batch\", leave=True)\n","        for batch in progress_bar:\n","            image = batch[\"image\"].to(device, non_blocking=True)\n","            mask = batch[\"mask\"].to(device, non_blocking=True)\n","\n","            with autocast('cuda'):\n","                pred = model(image)\n","\n","            pred_aug = d4_mask_batch(images = image, model = model, device = device)\n","            pred_aug_CRF = apply_crf_to_batch(images = image, probs = pred_aug)\n","\n","            #visualize_predictions(images = image , masks = mask, predictions = pred)\n","            #visualize_predictions(images = image , masks = mask, predictions = pred_aug)\n","            #visualize_predictions(images = image , masks = mask, predictions = pred_aug_CRF)\n","\n","            # Метрики\n","            TP_flood_batch, FP_flood_batch, TN_flood_batch, FN_flood_batch, TP_background_batch, FP_background_batch, TN_background_batch, FN_background_batch = calculate_TP_FP_TN_FN(pred, mask)\n","            TP_flood += TP_flood_batch\n","            FP_flood += FP_flood_batch\n","            TN_flood += TN_flood_batch\n","            FN_flood += FN_flood_batch\n","            TP_background += TP_background_batch\n","            FP_background += FP_background_batch\n","            TN_background += TN_background_batch\n","            FN_background += FN_background_batch\n","            TP_flood_batch, FP_flood_batch, TN_flood_batch, FN_flood_batch, TP_background_batch, FP_background_batch, TN_background_batch, FN_background_batch = calculate_TP_FP_TN_FN(pred_aug, mask)\n","            TP_flood_aug += TP_flood_batch\n","            FP_flood_aug += FP_flood_batch\n","            TN_flood_aug += TN_flood_batch\n","            FN_flood_aug += FN_flood_batch\n","            TP_background_aug += TP_background_batch\n","            FP_background_aug += FP_background_batch\n","            TN_background_aug += TN_background_batch\n","            FN_background_aug += FN_background_batch\n","            TP_flood_batch, FP_flood_batch, TN_flood_batch, FN_flood_batch, TP_background_batch, FP_background_batch, TN_background_batch, FN_background_batch = calculate_TP_FP_TN_FN(pred_aug_CRF, mask)\n","            TP_flood_aug_crf += TP_flood_batch\n","            FP_flood_aug_crf += FP_flood_batch\n","            TN_flood_aug_crf += TN_flood_batch\n","            FN_flood_aug_crf += FN_flood_batch\n","            TP_background_aug_crf += TP_background_batch\n","            FP_background_aug_crf += FP_background_batch\n","            TN_background_aug_crf += TN_background_batch\n","            FN_background_aug_crf += FN_background_batch\n","\n","    Accuracy, IoU_flood, IoU_background, IoU, Dice_flood, Dice_background, Dice, Precision_flood, Precision_background, Precision, Recall_flood, Recall_background, Recall, BalancedAccuracy = calculate_metrics(TP_flood = TP_flood, FP_flood = FP_flood, TN_flood = TN_flood, FN_flood = FN_flood, TP_background = TP_background, FP_background = FP_background, TN_background = TN_background, FN_background = FN_background)\n","    Accuracy_aug, IoU_flood_aug, IoU_background_aug, IoU_aug, Dice_flood_aug, Dice_background_aug, Dice_aug, Precision_flood_aug, Precision_background_aug, Precision_aug, Recall_flood_aug, Recall_background_aug, Recall_aug, BalancedAccuracy_aug = calculate_metrics(TP_flood = TP_flood_aug, FP_flood = FP_flood_aug, TN_flood = TN_flood_aug, FN_flood = FN_flood_aug, TP_background = TP_background_aug, FP_background = FP_background_aug, TN_background = TN_background_aug, FN_background = FN_background_aug)\n","    Accuracy_aug_crf, IoU_flood_aug_crf, IoU_background_aug_crf, IoU_aug_crf, Dice_flood_aug_crf, Dice_background_aug_crf, Dice_aug_crf, Precision_flood_aug_crf, Precision_background_aug_crf, Precision_aug_crf, Recall_flood_aug_crf, Recall_background_aug_crf, Recall_aug_crf, BalancedAccuracy_aug_crf = calculate_metrics(TP_flood = TP_flood_aug_crf, FP_flood = FP_flood_aug_crf, TN_flood = TN_flood_aug_crf, FN_flood = FN_flood_aug_crf, TP_background = TP_background_aug_crf, FP_background = FP_background_aug_crf, TN_background = TN_background_aug_crf, FN_background = FN_background_aug_crf)\n","    logger2.info(f\"WeightsEpoch: {checkpoint['epoch']}, TestBolivia IoU: {IoU:.4f}, TestB Accuracy: {Accuracy:.4f}, TestB Dice: {Dice:.4f}, TestB Precision: {Precision:.4f}, TestB Recall: {Recall:.4f}, TestB BalancedAccuracy: {BalancedAccuracy:.4f}, TestB IoU_flood: {IoU_flood:.4f}, TestB IoU_background: {IoU_background:.4f}, TestB Dice_flood: {Dice_flood:.4f}, TestB Dice_background: {Dice_background:.4f}, TestB Precision_flood: {Precision_flood:.4f}, TestB Precision_background: {Precision_background:.4f}, TestB Recall_flood: {Recall_flood:.4f}, TestB Recall_background: {Recall_background:.4f}\")\n","    logger2.info(f\"WeightsEpoch: {checkpoint['epoch']}, TestBolivia Aug IoU: {IoU_aug:.4f}, TestB Accuracy: {Accuracy_aug:.4f}, TestB Dice: {Dice_aug:.4f}, TestB Precision: {Precision_aug:.4f}, TestB Recall: {Recall_aug:.4f}, TestB BalancedAccuracy: {BalancedAccuracy_aug:.4f}, TestB IoU_flood: {IoU_flood_aug:.4f}, TestB IoU_background: {IoU_background_aug:.4f}, TestB Dice_flood: {Dice_flood_aug:.4f}, TestB Dice_background: {Dice_background_aug:.4f}, TestB Precision_flood: {Precision_flood_aug:.4f}, TestB Precision_background: {Precision_background_aug:.4f}, TestB Recall_flood: {Recall_flood_aug:.4f}, TestB Recall_background: {Recall_background_aug:.4f}\")\n","    logger2.info(f\"WeightsEpoch: {checkpoint['epoch']}, TestBolivia Aug CRF IoU: {IoU_aug_crf:.4f}, TestB Accuracy: {Accuracy_aug_crf:.4f}, TestB Dice: {Dice_aug_crf:.4f}, TestB Precision: {Precision_aug_crf:.4f}, TestB Recall: {Recall_aug_crf:.4f}, TestB BalancedAccuracy: {BalancedAccuracy_aug_crf:.4f}, TestB IoU_flood: {IoU_flood_aug_crf:.4f}, TestB IoU_background: {IoU_background_aug_crf:.4f}, TestB Dice_flood: {Dice_flood_aug_crf:.4f}, TestB Dice_background: {Dice_background_aug_crf:.4f}, TestB Precision_flood: {Precision_flood_aug_crf:.4f}, TestB Precision_background: {Precision_background_aug_crf:.4f}, TestB Recall_flood: {Recall_flood_aug_crf:.4f}, TestB Recall_background: {Recall_background_aug_crf:.4f}\")\n"],"metadata":{"id":"Zm1TDsW4xk8C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","\n","    folder_of_weights = \"Weights_RGB_NIR_HandLabeled\"\n","\n","    num_best_epoch = 0\n","    validation_iou = 0\n","    # Настройка логирования train\n","    logger1 = logging.getLogger(f\"training_logger\")\n","    logger1.setLevel(logging.INFO)\n","    # Формат логов\n","    formatter = logging.Formatter('%(message)s')\n","    # Вывод в консоль\n","    console_handler = logging.StreamHandler()\n","    console_handler.setFormatter(formatter)\n","    # Запись в файл\n","    file_handler = logging.FileHandler(f\"/content/drive/MyDrive/datasets_and_models/{folder}/{channels}_{data}_train.txt\", mode='a')\n","    file_handler.setFormatter(formatter)\n","    if not logger1.handlers:\n","      logger1.addHandler(console_handler)\n","      logger1.addHandler(file_handler)\n","\n","    # Настройка логирования test\n","    logger2 = logging.getLogger(f\"testing_logger\")\n","    logger2.setLevel(logging.INFO)\n","    # Формат логов\n","    formatter2 = logging.Formatter('%(message)s')\n","    # Вывод в консоль\n","    console_handler2 = logging.StreamHandler()\n","    console_handler2.setFormatter(formatter2)\n","    # Запись в файл\n","    file_handler2 = logging.FileHandler(f\"/content/drive/MyDrive/datasets_and_models/{folder}/{channels}_{data}_test.txt\", mode='a')\n","    file_handler2.setFormatter(formatter2)\n","    if not logger2.handlers:\n","      logger2.addHandler(console_handler2)\n","      logger2.addHandler(file_handler2)\n","\n","    train(num_epochs)\n","    test(num_best_epoch)\n","    test(num_epochs)"],"metadata":{"id":"2JY7-fD-tsXX","colab":{"base_uri":"https://localhost:8080/","height":500,"referenced_widgets":["ec37cae01f9e498895f741a645ef8fbe","3c21d80136bf41b599b8313581a70b2a","b0975abdaec945dabce8aa1e205698a8","f9ace37acdf14ebe97078f3b391d0c7c","7683632cb3894d45ba28dc2bbc86cac7","8f58e5cd287f4a55819552e80fa033ab","9b740bf336a644b9b2bb7a6d6bdfb46d","7b73b03f19ea4f8fa1d86075ae33139e","796d14cc101145cd8a63611fdb46063a","c2984f7c32a44040a8638779b15309ab","ff09981dc1974f0f994f6e068738eada","9d266d52540a40299a17f2c14cfaa44f","e8b46b6f54da49e7be44d042d4e5f8d2","950023f147cc4019a194d7749baf9ace","5512f79966f14b4faea2896ab0cc04a2","e30629dd4a954cb78c2b7573a5be3430","6da008d3add3417b8e9240bc7fc23afb","7244640cb5524c10b48d342bfa85e4a8","72a925e0665f44208c622b4fbb0cf83e","9cf41bc3cd7b46829a2ed80020a47250","5ca50a6169ed4ead9364cf4e6501a929","553846604bd6403dab7582a3a1d257b2"]},"executionInfo":{"status":"ok","timestamp":1747325298249,"user_tz":-180,"elapsed":65688,"user":{"displayName":"Oli","userId":"15742951886801697143"}},"outputId":"54104070-7d3b-409f-a7d9-529ac9ec93a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/106 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec37cae01f9e498895f741a645ef8fbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/14.2M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d266d52540a40299a17f2c14cfaa44f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Test: 100%|██████████| 23/23 [00:47<00:00,  2.07s/batch]\n","WeightsEpoch: 200, Test IoU: 0.8806, Test Accuracy: 0.9716, Test Dice: 0.9342, Test Precision: 0.9408, Test Recall: 0.9279, Test BalancedAccuracy: 0.9279, Test IoU_flood: 0.7931, Test IoU_background: 0.9682, Test Dice_flood: 0.8846, Test Dice_background: 0.9838, Test Precision_flood: 0.9002, Test Precision_background: 0.9814, Test Recall_flood: 0.8695, Test Recall_background: 0.9862\n","INFO:testing_logger:WeightsEpoch: 200, Test IoU: 0.8806, Test Accuracy: 0.9716, Test Dice: 0.9342, Test Precision: 0.9408, Test Recall: 0.9279, Test BalancedAccuracy: 0.9279, Test IoU_flood: 0.7931, Test IoU_background: 0.9682, Test Dice_flood: 0.8846, Test Dice_background: 0.9838, Test Precision_flood: 0.9002, Test Precision_background: 0.9814, Test Recall_flood: 0.8695, Test Recall_background: 0.9862\n","WeightsEpoch: 200, Test Aug IoU: 0.8833, Test Accuracy: 0.9724, Test Dice: 0.9358, Test Precision: 0.9430, Test Recall: 0.9290, Test BalancedAccuracy: 0.9290, Test IoU_flood: 0.7976, Test IoU_background: 0.9690, Test Dice_flood: 0.8874, Test Dice_background: 0.9842, Test Precision_flood: 0.9044, Test Precision_background: 0.9817, Test Recall_flood: 0.8711, Test Recall_background: 0.9868\n","INFO:testing_logger:WeightsEpoch: 200, Test Aug IoU: 0.8833, Test Accuracy: 0.9724, Test Dice: 0.9358, Test Precision: 0.9430, Test Recall: 0.9290, Test BalancedAccuracy: 0.9290, Test IoU_flood: 0.7976, Test IoU_background: 0.9690, Test Dice_flood: 0.8874, Test Dice_background: 0.9842, Test Precision_flood: 0.9044, Test Precision_background: 0.9817, Test Recall_flood: 0.8711, Test Recall_background: 0.9868\n","WeightsEpoch: 200, Test Aug CRF IoU: 0.8221, Test Accuracy: 0.9604, Test Dice: 0.8964, Test Precision: 0.9688, Test Recall: 0.8479, Test BalancedAccuracy: 0.8479, Test IoU_flood: 0.6876, Test IoU_background: 0.9566, Test Dice_flood: 0.8149, Test Dice_background: 0.9778, Test Precision_flood: 0.9791, Test Precision_background: 0.9585, Test Recall_flood: 0.6979, Test Recall_background: 0.9979\n","INFO:testing_logger:WeightsEpoch: 200, Test Aug CRF IoU: 0.8221, Test Accuracy: 0.9604, Test Dice: 0.8964, Test Precision: 0.9688, Test Recall: 0.8479, Test BalancedAccuracy: 0.8479, Test IoU_flood: 0.6876, Test IoU_background: 0.9566, Test Dice_flood: 0.8149, Test Dice_background: 0.9778, Test Precision_flood: 0.9791, Test Precision_background: 0.9585, Test Recall_flood: 0.6979, Test Recall_background: 0.9979\n"]},{"output_type":"stream","name":"stdout","text":["TP_flood = 2231246.0, FP_flood = 247280.0, TN_flood = 17703986.0, FN_flood = 334855.0\n","TP_flood_aug = 2235232.0, FP_flood_aug = 236260.0, TN_flood_aug = 17715006.0, FN_flood_aug = 330869.0\n","TP_floodaug_crf = 1790762.0, FP_floodaug_crf = 38135.0, TN_floodaug_crf = 17913131.0, FN_floodaug_crf = 775339.0\n"]},{"output_type":"stream","name":"stderr","text":["Test Bolivia: 100%|██████████| 4/4 [00:08<00:00,  2.02s/batch]\n","WeightsEpoch: 200, TestBolivia IoU: 0.8726, TestB Accuracy: 0.9640, TestB Dice: 0.9297, TestB Precision: 0.9496, TestB Recall: 0.9124, TestB BalancedAccuracy: 0.9124, TestB IoU_flood: 0.7867, TestB IoU_background: 0.9585, TestB Dice_flood: 0.8806, TestB Dice_background: 0.9788, TestB Precision_flood: 0.9294, TestB Precision_background: 0.9698, TestB Recall_flood: 0.8367, TestB Recall_background: 0.9880\n","INFO:testing_logger:WeightsEpoch: 200, TestBolivia IoU: 0.8726, TestB Accuracy: 0.9640, TestB Dice: 0.9297, TestB Precision: 0.9496, TestB Recall: 0.9124, TestB BalancedAccuracy: 0.9124, TestB IoU_flood: 0.7867, TestB IoU_background: 0.9585, TestB Dice_flood: 0.8806, TestB Dice_background: 0.9788, TestB Precision_flood: 0.9294, TestB Precision_background: 0.9698, TestB Recall_flood: 0.8367, TestB Recall_background: 0.9880\n","WeightsEpoch: 200, TestBolivia Aug IoU: 0.8816, TestB Accuracy: 0.9713, TestB Dice: 0.9348, TestB Precision: 0.9443, TestB Recall: 0.9259, TestB BalancedAccuracy: 0.9259, TestB IoU_flood: 0.7955, TestB IoU_background: 0.9677, TestB Dice_flood: 0.8861, TestB Dice_background: 0.9836, TestB Precision_flood: 0.9085, TestB Precision_background: 0.9801, TestB Recall_flood: 0.8648, TestB Recall_background: 0.9871\n","INFO:testing_logger:WeightsEpoch: 200, TestBolivia Aug IoU: 0.8816, TestB Accuracy: 0.9713, TestB Dice: 0.9348, TestB Precision: 0.9443, TestB Recall: 0.9259, TestB BalancedAccuracy: 0.9259, TestB IoU_flood: 0.7955, TestB IoU_background: 0.9677, TestB Dice_flood: 0.8861, TestB Dice_background: 0.9836, TestB Precision_flood: 0.9085, TestB Precision_background: 0.9801, TestB Recall_flood: 0.8648, TestB Recall_background: 0.9871\n","WeightsEpoch: 200, TestBolivia Aug CRF IoU: 0.8108, TestB Accuracy: 0.9567, TestB Dice: 0.8887, TestB Precision: 0.9677, TestB Recall: 0.8380, TestB BalancedAccuracy: 0.8380, TestB IoU_flood: 0.6691, TestB IoU_background: 0.9525, TestB Dice_flood: 0.8018, TestB Dice_background: 0.9757, TestB Precision_flood: 0.9811, TestB Precision_background: 0.9543, TestB Recall_flood: 0.6779, TestB Recall_background: 0.9981\n","INFO:testing_logger:WeightsEpoch: 200, TestBolivia Aug CRF IoU: 0.8108, TestB Accuracy: 0.9567, TestB Dice: 0.8887, TestB Precision: 0.9677, TestB Recall: 0.8380, TestB BalancedAccuracy: 0.8380, TestB IoU_flood: 0.6691, TestB IoU_background: 0.9525, TestB Dice_flood: 0.8018, TestB Dice_background: 0.9757, TestB Precision_flood: 0.9811, TestB Precision_background: 0.9543, TestB Recall_flood: 0.6779, TestB Recall_background: 0.9981\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm","authorship_tag":"ABX9TyONz14NRlYtwZ2wIXBAAfEu"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ec37cae01f9e498895f741a645ef8fbe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3c21d80136bf41b599b8313581a70b2a","IPY_MODEL_b0975abdaec945dabce8aa1e205698a8","IPY_MODEL_f9ace37acdf14ebe97078f3b391d0c7c"],"layout":"IPY_MODEL_7683632cb3894d45ba28dc2bbc86cac7"}},"3c21d80136bf41b599b8313581a70b2a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f58e5cd287f4a55819552e80fa033ab","placeholder":"​","style":"IPY_MODEL_9b740bf336a644b9b2bb7a6d6bdfb46d","value":"config.json: 100%"}},"b0975abdaec945dabce8aa1e205698a8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b73b03f19ea4f8fa1d86075ae33139e","max":106,"min":0,"orientation":"horizontal","style":"IPY_MODEL_796d14cc101145cd8a63611fdb46063a","value":106}},"f9ace37acdf14ebe97078f3b391d0c7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2984f7c32a44040a8638779b15309ab","placeholder":"​","style":"IPY_MODEL_ff09981dc1974f0f994f6e068738eada","value":" 106/106 [00:00&lt;00:00, 12.3kB/s]"}},"7683632cb3894d45ba28dc2bbc86cac7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f58e5cd287f4a55819552e80fa033ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b740bf336a644b9b2bb7a6d6bdfb46d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b73b03f19ea4f8fa1d86075ae33139e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"796d14cc101145cd8a63611fdb46063a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c2984f7c32a44040a8638779b15309ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff09981dc1974f0f994f6e068738eada":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d266d52540a40299a17f2c14cfaa44f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e8b46b6f54da49e7be44d042d4e5f8d2","IPY_MODEL_950023f147cc4019a194d7749baf9ace","IPY_MODEL_5512f79966f14b4faea2896ab0cc04a2"],"layout":"IPY_MODEL_e30629dd4a954cb78c2b7573a5be3430"}},"e8b46b6f54da49e7be44d042d4e5f8d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6da008d3add3417b8e9240bc7fc23afb","placeholder":"​","style":"IPY_MODEL_7244640cb5524c10b48d342bfa85e4a8","value":"model.safetensors: 100%"}},"950023f147cc4019a194d7749baf9ace":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_72a925e0665f44208c622b4fbb0cf83e","max":14186200,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9cf41bc3cd7b46829a2ed80020a47250","value":14186200}},"5512f79966f14b4faea2896ab0cc04a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ca50a6169ed4ead9364cf4e6501a929","placeholder":"​","style":"IPY_MODEL_553846604bd6403dab7582a3a1d257b2","value":" 14.2M/14.2M [00:00&lt;00:00, 103MB/s]"}},"e30629dd4a954cb78c2b7573a5be3430":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6da008d3add3417b8e9240bc7fc23afb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7244640cb5524c10b48d342bfa85e4a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72a925e0665f44208c622b4fbb0cf83e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cf41bc3cd7b46829a2ed80020a47250":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5ca50a6169ed4ead9364cf4e6501a929":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"553846604bd6403dab7582a3a1d257b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}